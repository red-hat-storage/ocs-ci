import logging
import pytest
from threading import Thread

from ocs_ci.ocs import constants
from ocs_ci.helpers.helpers import modify_deployment_replica_count
from ocs_ci.ocs.resources.deployment import get_mon_deployments
from ocs_ci.ocs.resources.pvc import get_pvc_objs
from ocs_ci.utility.utils import ceph_health_check
from ocs_ci.ocs.resources.pod import get_ceph_tools_pod
from ocs_ci.ocs.resources.storage_cluster import ceph_mon_dump
from ocs_ci.framework.pytest_customization.marks import tier4a


log = logging.getLogger(__name__)


@tier4a
@pytest.mark.polarionid("OCS-4942")
class TestMonCrashRecoveryScenario:
    def teardown_resources(self):
        """Teardown function to scale deployments back to 1 replica."""
        for dep in ["ocs-operator", "rook-ceph-operator"]:
            modify_deployment_replica_count(dep, 1)

    def test_mon_crash_recovery_scenario(self, pvc_factory, pod_factory, request):
        """
        Verifies system behavior when a crash occurs in the mon-x deployment.

        Steps:
            1. Start the IO workload in the background.
            2. Scale down the deployments of the operators and of the mon-x.
            3. Delete the Deployment of rook-ceph-mon-x and pvc rook-ceph-mon-x
            4. Scale up the operators to replicas = 1
            5. Verify 'ceph mon dump' command is working.
            6. Check for the any crash has generated.
        """

        mon_obj = get_mon_deployments()[0]
        mon_name = mon_obj.name
        mon_pvc = mon_obj.data["metadata"]["labels"]["pvc_name"]
        mon_pvc_obj = get_pvc_objs([mon_pvc])[0]

        # Step1:  Creating Workload On the Cluster.
        pvc_obj = pvc_factory(
            interface=constants.CEPHBLOCKPOOL, status=constants.STATUS_BOUND
        )
        pod_obj = pod_factory(interface=constants.CEPHBLOCKPOOL, pvc=pvc_obj)

        kwargs = {
            "storage_type": "fs",
            "size": "10G",
            "runtime": 200,
        }

        io_thread = Thread(
            target=pod_obj.run_io,
            name="io_thread",
            kwargs=kwargs,
        )
        io_thread.start()

        # Step2: Scale down the deployments of the operators and of the mon-x.
        deployment_list = ["ocs-operator", "rook-ceph-operator", mon_name]
        log.info(
            f"Scaling down deployments: {','.join(deployment_list)} to 0 replicas..."
        )
        for deployment in deployment_list:
            assert modify_deployment_replica_count(
                deployment, 0
            ), f"Fail to scale {deployment} to replica count: 0"

        request.addfinalizer(self.teardown_resources)

        # Step 3: Deleting the mon deployment
        log.info(f"Deleting mon deployment {mon_name}")
        mon_obj.delete()
        assert mon_obj.is_deleted, f"Mon Deployment {mon_name} is not deleted."

        # Step 3: Delete PVC associated with the MON.
        log.info(f"deleting pvc {mon_pvc_obj.name} associated with mon {mon_name}")
        mon_pvc_obj.delete()
        assert mon_pvc_obj.ocp.wait_for_delete(pvc_obj.name)

        # Step 4: Scale up the operators to replicas = 1
        log.info("Scaling up deployments to 1 replica...")
        for dep in ["ocs-operator", "rook-ceph-operator"]:
            assert modify_deployment_replica_count(
                dep, 1
            ), f"Failed to scale deployment {dep} to replicas : 1"

        # Waiting for IO to be completed.
        io_thread.join()

        # Check Ceph cluster health
        log.info("Checking Ceph cluster health...")
        assert ceph_health_check(tries=90, delay=15), "Ceph cluster health is not OK"

        # Step 5: Verify 'ceph mon dump' output has the recovered mon information.
        log.info(
            f"Verifying 'ceph mon dump' command output has information about recovered mon: {mon_name} "
        )
        mon_dump = ceph_mon_dump()
        assert [
            mon for mon in mon_dump["mons"] if mon["name"] == mon_name.split("-")[-1]
        ], f"'ceph mon dump' command output dont have the information about recovered mon: {mon_name}"

        # Step 6: Check If any crash has generated.
        log.info("Checking if the new crash has generated by the ceph.")
        toolbox = get_ceph_tools_pod()
        crash = toolbox.exec_ceph_cmd("ceph crash ls-new")
        assert not crash, f"Ceph cluster has generated crash {' '.join(crash[0])}"
