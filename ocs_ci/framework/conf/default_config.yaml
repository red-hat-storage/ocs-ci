---
# This is the default configuration file which will be merged with file passed
# by:
#
# * --ocsci-conf file.yaml parameter.
# * --cluster-conf cluster.yaml parameter - this will be rendered under
#   ENV_DATA section
#
# Each section in this file will be available as an attribute of the
# framework.config object.
#
# ------------------------------------------------------------------------

# in this RUN section we will keep default parameters for run of OCS-CI
RUN:
  username: 'kubeadmin'
  password_location: 'auth/kubeadmin-password'
  log_dir: "/tmp"
  run_id: null  # this will be redefined in the execution
  kubeconfig_location: 'auth/kubeconfig' # relative from cluster_dir
  cli_params: {}  # this will be filled with CLI parameters data
  # If the client version ends with .nightly, the version will be exposed
  # to the latest accepted OCP nightly build version
  client_version: '4.2.0-0.nightly'
  bin_dir: './bin'
  google_api_secret: '~/.ocs-ci/google_api_secret.json'
  rook_branch: "master"
  # We can also specify the tag or specific commit id to checkout by changin
  # following parameter in custom config file:
  # rook_to_checkout: "commit_id or tag_name"

# In this section we are storing all deployment related configuration but not
# the environment related data as those are defined in ENV_DATA section.
DEPLOYMENT:
  # if the installer version ends with .nightly, the version will be exposed
  # to the latest accepted OCP nightly build version. You can also use the
  # specific build version like: "4.2.0-0.nightly-2019-08-06-195545"
  installer_version: "4.2.0-0.nightly"
  force_download_installer: True
  force_download_client: True
  # You can overwrite csv channel version by following parameter
  # ocs_csv_channel: "alpha"
  ocs_operator_storage_cluster_cr: "https://raw.githubusercontent.com/openshift/ocs-operator/master/deploy/crds/ocs_v1_storagecluster_cr.yaml"
  ocs_operator_olm: "https://raw.githubusercontent.com/openshift/ocs-operator/master/deploy/deploy-with-olm.yaml"
  # you can overwrite the image for ocs operator catalog souce by following parameter:
  # ocs_operator_image: "quay.io/ocs-dev/ocs-registry:latest"
  ocs_operator_nodes_to_label: 3
  # This is described as a WA for minimal configuration 3/3 worker/master
  # nodes. See: https://github.com/openshift/ocs-operator
  ocs_operator_nodes_to_tain: 0
  ocs_operator_deployment: True
  ssh_key: "~/.ssh/libra.pub"
  force_deploy_multiple_clusters: False

# Section for reporting configuration
REPORTING:
  email:
    address: "ocs-ci@redhat.com"
  polarion:
    project_id: "OpenShiftContainerStorage"
  # Upstream: 'US' or Downstream: 'DS', used only for reporting (Test Run Name)
  us_ds: 'US'
  ocp_must_gather_image: "quay.io/openshift/origin-must-gather"
  ocs_must_gather_image: "quay.io/ocs-dev/ocs-must-gather"

# This is the default information about environment. Will be overwritten with
# --cluster-conf file.yaml data you will pass to the pytest.
ENV_DATA:
  cluster_name: null  # will be changed in ocscilib plugin
  storage_cluster_name: 'rook-ceph'
  storage_device_sets_name: "storageDeviceSets"
  cluster_namespace: 'openshift-storage'
  monitoring_enabled: true
  persistent-monitoring: true
  platform: 'AWS'
  deployment_type: 'ipi'
  region: 'us-east-2'
  base_domain: 'qe.rh-ocs.com'
  master_instance_type: 'm4.xlarge'
  worker_instance_type: 'm4.xlarge'
  skip_ocp_deployment: false
  skip_ocs_deployment: false
  # Do not change to specific version like v14.2.1-20190430 if not needed
  # cause we don't need to update it each time new 14.x version is released
  # but only once when move to new version like v15.
  ceph_image: 'ceph/ceph:v14.2.3-20190904'
  rook_image: 'rook/ceph:master'
  worker_instance_type: 'm4.xlarge'
  # uncomment to use custom directory for storing measurement data related to
  # monitoring tests, otherwise generate temporary directory for each test run
  # measurement_dir: '/tmp/ocs_ci_monitoring_measurement/'