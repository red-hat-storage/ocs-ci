tests:
- test:
    name: install ceph pre-requisites
    module: install_prereq.py
    abort-on-fail: True
- test:
    name: ceph ansible install rhcs 2 stable
    module: test_ansible.py
    config:
      use_cdn: True
      build: '2.0'
      ansi_config:
        ceph_test: True
        ceph_origin: repository
        ceph_repository: rhcs
        ceph_repository_type: cdn
        ceph_rhcs_version: 2
        ceph_stable_release: jewel
        ceph_rhcs_cdn_debian_repo: https://redhat:OgYZNpkj6jZAIF20XFZW0gnnwYBjYcmt7PeY76bLHec9@rhcs.download.redhat.com
        ceph_rhcs_cdn_debian_repo_version: /2-updates/
        osd_scenario: collocated
        osd_auto_discovery: False
        journal_size: 1024
        copy_admin_key: True
        ceph_conf_overrides:
          global:
            osd_pool_default_pg_num: 128
            osd_default_pool_size: 2
            osd_pool_default_pgp_num: 128
            mon_max_pg_per_osd: 4096
            mon_allow_pool_delete: True
          client:
            rgw crypt require ssl: false
            rgw crypt s3 kms encryption keys: testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo=
              testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
    desc: test cluster setup using ceph-ansible
    abort-on-fail: True
- test:
    name: ceph ansible upgrade to rhcs 3 nightly
    polarion-id: CEPH-83571475
    module: test_ansible_upgrade.py
    config:
      ansi_config:
        ceph_test: True
        ceph_origin: distro
        ceph_repository: rhcs
        ceph_rhcs_version: 3
        ceph_stable_release: luminous
        ceph_rhcs_cdn_debian_repo: https://redhat:OgYZNpkj6jZAIF20XFZW0gnnwYBjYcmt7PeY76bLHec9@rhcs.download.redhat.com
        ceph_rhcs_cdn_debian_repo_version: /3-updates/
        osd_scenario: collocated
        osd_auto_discovery: True
        upgrade_ceph_packages: True
        copy_admin_key: True
        ceph_conf_overrides:
          global:
            osd_pool_default_pg_num: 128
            osd_default_pool_size: 2
            osd_pool_default_pgp_num: 128
            mon_max_pg_per_osd: 4096
            mon_allow_pool_delete: True
          client:
            rgw crypt require ssl: false
            rgw crypt s3 kms encryption keys: testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo=
              testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
    desc: Test Ceph-Ansible rolling update - 2.x -> 3.x
    abort-on-fail: True
- test:
    name: librbd workunit
    module: test_workunit.py
    config:
      test_name: rbd/test_librbd_python.sh
      branch: luminous
      role: mon
    desc: Test librbd unit tests
- test:
    name: rbd cli image
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_image.py
      branch: master
    polarion-id: CEPH-83572722
    desc: CLI validation for image related commands
- test:
    name: rbd cli snap_clone
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_snap_clone.py
      branch: master
    polarion-id: CEPH-83572725
    desc: CLI validation for snap and clone related commands
- test:
    name: rbd cli misc
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_misc.py
      branch: master
    polarion-id: CEPH-83572724
    desc: CLI validation for miscellaneous rbd commands
- test:
    name: rbd cli import_export
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_import_export_diff.py
      branch: master
    polarion-id: CEPH-83572723
    desc: CLI validation for import, export and diff related commands
- test:
    name: check-ceph-health
    module: exec.py
    config:
      cmd: ceph -s
      sudo: True
    desc: Check for ceph health debug info
- test:
    name: rados_bench_test
    module: radosbench.py
    config:
      pg_num: '128'
      pool_type: 'normal'
    desc: run rados bench for 360 - normal profile
- test:
    name: s3 tests
    module: test_s3.py
    config:
      branch: ceph-luminous
    desc: execution of s3 tests against radosgw
- test:
    name: ceph ansible purge
    module: purge_cluster.py
    desc: Purge ceph cluster
    abort-on-fail: True
    recreate-cluster: True

- test:
    name: install ceph pre-requisites
    module: install_prereq.py
    abort-on-fail: True
- test:
    name: ceph ansible install rhcs 2 stable
    module: test_ansible.py
    config:
      use_cdn: True
      build: '2.0'
      ansi_config:
        ceph_test: True
        ceph_origin: repository
        ceph_repository: rhcs
        ceph_repository_type: cdn
        ceph_rhcs_version: 2
        ceph_stable_release: jewel
        ceph_rhcs_cdn_debian_repo: https://redhat:OgYZNpkj6jZAIF20XFZW0gnnwYBjYcmt7PeY76bLHec9@rhcs.download.redhat.com
        ceph_rhcs_cdn_debian_repo_version: /2-updates/
        osd_scenario: collocated
        osd_auto_discovery: False
        journal_size: 1024
        copy_admin_key: True
        ceph_conf_overrides:
          global:
            osd_pool_default_pg_num: 128
            osd_default_pool_size: 2
            osd_pool_default_pgp_num: 128
            mon_max_pg_per_osd: 4096
            mon_allow_pool_delete: True
          client:
            rgw crypt require ssl: false
            rgw crypt s3 kms encryption keys: testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo=
              testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
    desc: test cluster setup using ceph-ansible
    abort-on-fail: True
- test:
    name: ceph ansible upgrade to rhcs 3 stable
    module: test_ansible_upgrade.py
    config:
      use_cdn: True
      build: '3.0'
      ansi_config:
        ceph_test: True
        ceph_origin: repository
        ceph_repository: rhcs
        ceph_repository_type: cdn
        ceph_rhcs_version: 3
        ceph_stable_release: luminous
        ceph_rhcs_cdn_debian_repo: https://redhat:OgYZNpkj6jZAIF20XFZW0gnnwYBjYcmt7PeY76bLHec9@rhcs.download.redhat.com
        ceph_rhcs_cdn_debian_repo_version: /3-updates/
        osd_scenario: collocated
        osd_auto_discovery: False
        copy_admin_key: True
        upgrade_ceph_packages: True
        ceph_conf_overrides:
          global:
            osd_pool_default_pg_num: 128
            osd_default_pool_size: 2
            osd_pool_default_pgp_num: 128
            mon_max_pg_per_osd: 4096
            mon_allow_pool_delete: True
    desc: test rolling upgrade using ceph-ansible
    abort-on-fail: True
- test:
    name: ceph ansible upgrade to rhcs 3 nightly
    polarion-id: CEPH-83571476
    module: test_ansible_upgrade.py
    config:
      ansi_config:
        ceph_test: True
        ceph_origin: distro
        ceph_repository: rhcs
        ceph_stable_release: luminous
        ceph_rhcs_cdn_debian_repo: https://redhat:OgYZNpkj6jZAIF20XFZW0gnnwYBjYcmt7PeY76bLHec9@rhcs.download.redhat.com
        ceph_rhcs_cdn_debian_repo_version: /3-updates/
        osd_scenario: collocated
        osd_auto_discovery: False
        copy_admin_key: True
        upgrade_ceph_packages: True
        ceph_conf_overrides:
          global:
            osd_pool_default_pg_num: 128
            osd_default_pool_size: 2
            osd_pool_default_pgp_num: 128
            mon_max_pg_per_osd: 4096
            mon_allow_pool_delete: True
          client:
            rgw crypt require ssl: false
            rgw crypt s3 kms encryption keys: testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo=
              testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
    desc: Test Ceph-Ansible rolling update - 2.x -> 3.0 - 3.x
    abort-on-fail: True
- test:
    name: librbd workunit
    module: test_workunit.py
    config:
      test_name: rbd/test_librbd_python.sh
      branch: luminous
      role: mon
    desc: Test librbd unit tests
- test:
    name: rbd cli image
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_image.py
      branch: master
    polarion-id: CEPH-83572722
    desc: CLI validation for image related commands
- test:
    name: rbd cli snap_clone
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_snap_clone.py
      branch: master
    polarion-id: CEPH-83572725
    desc: CLI validation for snap and clone related commands
- test:
    name: rbd cli misc
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_misc.py
      branch: master
    polarion-id: CEPH-83572724
    desc: CLI validation for miscellaneous rbd commands
- test:
    name: rbd cli import_export
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_import_export_diff.py
      branch: master
    polarion-id: CEPH-83572723
    desc: CLI validation for import, export and diff related commands
- test:
    name: check-ceph-health
    module: exec.py
    config:
      cmd: ceph -s
      sudo: True
    desc: Check for ceph health debug info
- test:
    name: rados_bench_test
    module: radosbench.py
    config:
      pg_num: '128'
      pool_type: 'normal'
    desc: run rados bench for 360 - normal profile
- test:
    name: s3 tests
    module: test_s3.py
    config:
      branch: ceph-luminous
    desc: execution of s3 tests against radosgw
- test:
    name: ceph ansible purge
    module: purge_cluster.py
    desc: Purge ceph cluster
    abort-on-fail: True
    recreate-cluster: True

- test:
    name: install ceph pre-requisites
    module: install_prereq.py
    abort-on-fail: True
- test:
    name: ceph ansible install rhcs 3 stable
    module: test_ansible.py
    config:
      use_cdn: True
      build: '3.0'
      ansi_config:
        ceph_test: True
        ceph_origin: repository
        ceph_repository: rhcs
        ceph_repository_type: cdn
        ceph_rhcs_version: 3
        ceph_stable_release: luminous
        ceph_rhcs_cdn_debian_repo: https://redhat:OgYZNpkj6jZAIF20XFZW0gnnwYBjYcmt7PeY76bLHec9@rhcs.download.redhat.com
        ceph_rhcs_cdn_debian_repo_version: /3-updates/
        osd_scenario: collocated
        osd_auto_discovery: False
        copy_admin_key: True
        ceph_conf_overrides:
          global:
            osd_pool_default_pg_num: 128
            osd_default_pool_size: 2
            osd_pool_default_pgp_num: 128
            mon_max_pg_per_osd: 4096
            mon_allow_pool_delete: True
    desc: test cluster setup using ceph-ansible
    abort-on-fail: True
- test:
    name: ceph ansible upgrade to rhcs 3 nightly
    polarion-id: CEPH-83571477
    module: test_ansible_upgrade.py
    config:
      ansi_config:
        ceph_test: True
        ceph_origin: distro
        ceph_repository: rhcs
        ceph_stable_release: luminous
        ceph_rhcs_cdn_debian_repo: https://redhat:OgYZNpkj6jZAIF20XFZW0gnnwYBjYcmt7PeY76bLHec9@rhcs.download.redhat.com
        ceph_rhcs_cdn_debian_repo_version: /3-updates/
        osd_scenario: collocated
        osd_auto_discovery: False
        copy_admin_key: True
        upgrade_ceph_packages: True
        ceph_conf_overrides:
          global:
            osd_pool_default_pg_num: 128
            osd_default_pool_size: 2
            osd_pool_default_pgp_num: 128
            mon_max_pg_per_osd: 4096
            mon_allow_pool_delete: True
          client:
            rgw crypt require ssl: false
            rgw crypt s3 kms encryption keys: testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo=
              testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
    desc: Ceph-Ansible rolling update - 3.0 -> 3.x
    abort-on-fail: True
- test:
    name: librbd workunit
    module: test_workunit.py
    config:
      test_name: rbd/test_librbd_python.sh
      branch: luminous
      role: mon
    desc: Test librbd unit tests
- test:
    name: rbd cli image
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_image.py
      branch: master
    polarion-id: CEPH-83572722
    desc: CLI validation for image related commands
- test:
    name: rbd cli snap_clone
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_snap_clone.py
      branch: master
    polarion-id: CEPH-83572725
    desc: CLI validation for snap and clone related commands
- test:
    name: rbd cli misc
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_misc.py
      branch: master
    polarion-id: CEPH-83572724
    desc: CLI validation for miscellaneous rbd commands
- test:
    name: rbd cli import_export
    module: rbd_system.py
    config:
      test_name: cli/rbd_cli_import_export_diff.py
      branch: master
    polarion-id: CEPH-83572723
    desc: CLI validation for import, export and diff related commands
- test:
    name: check-ceph-health
    module: exec.py
    config:
      cmd: ceph -s
      sudo: True
    desc: Check for ceph health debug info
- test:
    name: rados_bench_test
    module: radosbench.py
    config:
      pg_num: '128'
      pool_type: 'normal'
    desc: run rados bench for 360 - normal profile
- test:
    name: s3 tests
    module: test_s3.py
    config:
      branch: ceph-luminous
    desc: execution of s3 tests against radosgw
- test:
    name: ceph ansible purge
    module: purge_cluster.py
    desc: Purge ceph cluster
    destroy-cluster: True
